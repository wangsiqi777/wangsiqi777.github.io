<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>大创 on Daqi23333的杂货小记</title>
    <link>https://wangsiqi777.github.io/categories/%E5%A4%A7%E5%88%9B/</link>
    <description>Recent content in 大创 on Daqi23333的杂货小记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 29 Apr 2019 18:58:17 +0800</lastBuildDate>
    
	<atom:link href="https://wangsiqi777.github.io/categories/%E5%A4%A7%E5%88%9B/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bp_Rnn_LSTM</title>
      <link>https://wangsiqi777.github.io/post/Bp_Rnn/</link>
      <pubDate>Mon, 29 Apr 2019 18:58:17 +0800</pubDate>
      
      <guid>https://wangsiqi777.github.io/post/Bp_Rnn/</guid>
      <description>BP BP神经网络是线性权重的激活函数模型，即输入一个向量，对向量进行加权处理后输入到隐含层神经元的激活函数当中去，再将函数的输出值进行加权处理最后得到输出层的值。 使用梯度下降方法对参数进行优化。但是该方法在很多情形下无法达到全局最优解，只能达到部分最优解，容易出现“局部收敛”等问题</description>
    </item>
    
    <item>
      <title>LSTM</title>
      <link>https://wangsiqi777.github.io/post/LSTM/</link>
      <pubDate>Sun, 28 Apr 2019 00:31:08 +0800</pubDate>
      
      <guid>https://wangsiqi777.github.io/post/LSTM/</guid>
      <description>LSTM基本概念 长短期记忆模型（long-short term memory）是一种特殊的RNN模型，是为了解决RNN模型梯度弥散的问题而提出的；在传统的RNN中，训练算法使用的是BPTT，当时间比较长时，需要回传的残差会指数下降，导致网络权重更新缓慢，无法体现出RNN的长期记忆的效果，因</description>
    </item>
    
    <item>
      <title>为什么会有“梯度消失”和“梯度爆炸”现象？</title>
      <link>https://wangsiqi777.github.io/post/%E6%A2%AF%E5%BA%A6/</link>
      <pubDate>Sat, 27 Apr 2019 00:31:08 +0800</pubDate>
      
      <guid>https://wangsiqi777.github.io/post/%E6%A2%AF%E5%BA%A6/</guid>
      <description>1 梯度消失和梯度爆炸的根本原因 梯度消失/爆炸的根源—–深度神经网络和反向传播。 梯度消失经常出现，一是在深层网络中，二是采用了不合适的损失函数，比如sigmoid,tanh。 梯度爆炸一般出现在深层网络和权值初始化值太大的情况下 在于前层上的梯度的计算来自于后层上梯度的乘积（链式法则）</description>
    </item>
    
    <item>
      <title>不同类别的数据处理——KDDCUP数据预处理（python实现）</title>
      <link>https://wangsiqi777.github.io/post/%E9%AB%98%E6%95%B0%E9%87%8F%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 26 Apr 2019 00:31:08 +0800</pubDate>
      
      <guid>https://wangsiqi777.github.io/post/%E9%AB%98%E6%95%B0%E9%87%8F%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86/</guid>
      <description>机器学习中的特征类别：连续型特征和离散型特征 拿到获取的原始特征，必须对每一特征分别进行归一化，比如，特征A的取值范围是[-1000,1000]，特征B的取值范围是[-1,1].如果使用logistic回归，w1x1+w2x2，因为x1的取值太大了，所以x2基本起不了作用。所以，必</description>
    </item>
    
    <item>
      <title>KDD CUP 99数据集介绍</title>
      <link>https://wangsiqi777.github.io/post/KDD-CUP-99%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Thu, 25 Apr 2019 00:31:08 +0800</pubDate>
      
      <guid>https://wangsiqi777.github.io/post/KDD-CUP-99%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/</guid>
      <description>KDD CUP 99 dataset：KDD竞赛在1999年举行的数据挖掘与知识发现竞赛时采用的数据集。 该数据集收集了9周时间的TCPdump网络连接和系统审计数据，仿真各种用户类型、各种不同的网络流量和攻击手段。 1.KDDCup99入侵检测实验数据的标识类型 标识类型 含义 Normal 正常记录 DOS 拒绝服务攻击</description>
    </item>
    
  </channel>
</rss>